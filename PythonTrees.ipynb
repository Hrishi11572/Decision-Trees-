{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "160d6f56",
   "metadata": {},
   "source": [
    "# Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d87cce80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node(feature=1,value=5, label=None)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import graphviz\n",
    "\n",
    "\n",
    "class Node:\n",
    "    def __init__(self,feature=None,value=None,rightchild=None,leftchild=None,leaflabel=None):\n",
    "        self.feature=feature\n",
    "        self.value=value\n",
    "        self.rightchild=rightchild\n",
    "        self.leftchild=leftchild\n",
    "        self.leaflabel=leaflabel\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"Node(feature={self.feature},value={self.value}, label={self.leaflabel})\")\n",
    "\n",
    "def CalculateEntropy(labels):\n",
    "    OccurenceCounts = np.bincount(labels)\n",
    "    probs = OccurenceCounts/len(labels)\n",
    "    \n",
    "    entropy = -np.sum(\n",
    "        [p * np.log2(p) for p in probs if p > 0]\n",
    "        )\n",
    "    return entropy\n",
    "\n",
    "def split_data(data,labels,feature,value):\n",
    "    '''\n",
    "        data = the original data to split \n",
    "        labels = the label of the data \n",
    "        feature = the features of the data or called as attributes \n",
    "        value = the value to compare with the features \n",
    "        \n",
    "        we already know that each node has a (feature, value) pair\n",
    "    '''\n",
    "    right_indices = np.where(data[: , feature] > value)[0]\n",
    "    left_indices = np.where(data[: , feature] <= value)[0]\n",
    "    \n",
    "    right_data= data[right_indices]\n",
    "    left_data= data[left_indices]\n",
    "    right_labels = labels[right_indices]\n",
    "    left_labels = labels[left_indices]\n",
    "    \n",
    "    return (right_data,right_labels,left_data,left_labels)\n",
    "    \n",
    "def buildTree(X,y):\n",
    "    '''\n",
    "        X : data set -> nd.array\n",
    "        y : labels corresponding to the data set -> 1D array \n",
    "    '''\n",
    "    \n",
    "    # base case -> leaf node \n",
    "    if(len(set(y)) == 1):\n",
    "        return Node(leaflabel=y[0])\n",
    "    else:\n",
    "        \n",
    "        #internal node\n",
    "        bestfeature=None\n",
    "        bestValue=None\n",
    "        bestSplit=None\n",
    "        bestGain = -np.inf \n",
    "        \n",
    "        CurrentEntropy = CalculateEntropy(y) #of the data-set \n",
    "        n_features= X.shape[1]\n",
    "        \n",
    "        for feature in range(n_features):\n",
    "            Values = np.unique(X[:, feature])\n",
    "            for value in Values:\n",
    "                right_data, right_labels, left_data, left_labels = split_data(X,y,feature,value)\n",
    "                if len(right_labels)==0 and len(left_labels)==0:\n",
    "                    continue\n",
    "                \n",
    "                entropy_right = CalculateEntropy(right_labels)\n",
    "                entropy_left= CalculateEntropy(left_labels)\n",
    "                \n",
    "                Information_gain  = CurrentEntropy - (\n",
    "                        entropy_right * (len(right_labels)/len(y))\n",
    "                        +\n",
    "                        entropy_left  * (len(left_labels)/len(y))\n",
    "                    )\n",
    "                \n",
    "                if(Information_gain > bestGain):\n",
    "                    bestGain = Information_gain\n",
    "                    bestfeature = feature\n",
    "                    bestValue = value\n",
    "                    bestSplit = (right_data, right_labels, left_data, left_labels)\n",
    "        \n",
    "        # if no best split was found ,then return the leaf node with class = majority class \n",
    "        if bestSplit == None :\n",
    "            majority_label = np.bincount(y).argmax()\n",
    "            node = Node(leaflabel=majority_label)\n",
    "            return node \n",
    "        \n",
    "        # add the node to the tree\n",
    "        right_data, right_labels, left_data, left_labels = bestSplit\n",
    "        \n",
    "        rightchild = buildTree(right_data,right_labels)\n",
    "        leftchild = buildTree(left_data,left_labels)\n",
    "        \n",
    "        root = Node(bestfeature,bestValue,rightchild,leftchild)\n",
    "        return root     \n",
    "\n",
    "def predict(tree , sample):\n",
    "    root = tree \n",
    "    \n",
    "    while True:\n",
    "        if (root.rightchild is not None) or (root.leftchild is not None):\n",
    "            attribute = root.feature\n",
    "            if sample[attribute] >= root.value : \n",
    "                root = root.rightchild\n",
    "            else :\n",
    "                root = root.leftchild\n",
    "        else :\n",
    "            break \n",
    "    \n",
    "    if root.rightchild == None and root.leftchild == None :\n",
    "        return root.leaflabel\n",
    "        \n",
    "\n",
    "def visualize_tree(node , dot=None):\n",
    "    \"\"\"\n",
    "    Recursively creates a DOT representation of the decision tree.\n",
    "    \"\"\"\n",
    "    if dot is None :\n",
    "        dot = graphviz.Digraph()\n",
    "\n",
    "    # Create a unique node id for the current node\n",
    "    node_id = str(id(node))\n",
    "    \n",
    "    # If the node is a leaf, just add the label\n",
    "    if node.leaflabel is not None:\n",
    "        dot.node(node_id, label=str(node.leaflabel), shape='ellipse', color='blue')\n",
    "    else:\n",
    "        # Add internal node with feature and value\n",
    "        dot.node(node_id, label=f\"X{node.feature} <= {node.value:.2f}\", shape='box')\n",
    "        \n",
    "        if node.leftchild:\n",
    "            left_id = str(id(node.leftchild))\n",
    "            dot.node(left_id, label=str(node.leftchild), shape='ellipse')\n",
    "            dot.edge(node_id, left_id, label=\"True\")\n",
    "            visualize_tree(node.leftchild, dot)\n",
    "        \n",
    "        if node.rightchild:\n",
    "            right_id = str(id(node.rightchild))\n",
    "            dot.node(right_id, label=str(node.rightchild), shape='ellipse')\n",
    "            dot.edge(node_id, right_id, label=\"False\")\n",
    "            visualize_tree(node.rightchild, dot)\n",
    "\n",
    "    return dot\n",
    "                \n",
    "if __name__ == '__main__':\n",
    "    X = np.array([[2, 3, 1, 5],\n",
    "                  [3, 2, 2, 1],\n",
    "                  [1, 4, 3, 2],\n",
    "                  [4, 1, 1, 3],\n",
    "                  [5, 6, 2, 1],\n",
    "                  [7, 8, 3, 4],\n",
    "                  [6, 5, 1, 6],\n",
    "                  [8, 7, 2, 3],\n",
    "                  [2, 5, 3, 4],\n",
    "                  [3, 6, 1, 2]])\n",
    "\n",
    "    y = np.array([0, 0, 0, 1, 1, 1, 0, 1, 0, 1])  # Class labels for each instance\n",
    "    \n",
    "    tree = buildTree(X, y)\n",
    "    print(tree)\n",
    "    \n",
    "    sample= np.array([1, 1])\n",
    "    print(predict(tree , sample))\n",
    "    \n",
    "    dot = visualize_tree(tree)\n",
    "    dot.render(\"decision_tree\", format=\"png\", view=True)  # This will create a PNG image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95c1993",
   "metadata": {},
   "source": [
    "# General Binary TreeeI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
